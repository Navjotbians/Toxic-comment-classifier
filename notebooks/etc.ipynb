{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORvBQcJ8k6vo"
   },
   "source": [
    "## Data exploration before pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8AP6pmPjk6v1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uxi--Zy7k6v3"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J31Mx7R0lkk4",
    "outputId": "78a324e3-a654-40b1-a194-2f73731c6590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')\r",
    "# \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_LbpeVG1k6v3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset with toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract dataset with toxic label\n",
    "df_toxic = df[df['toxic'] == 1]\n",
    "#Reseting the index\n",
    "df_toxic.set_index(['id'], inplace = True)\n",
    "df_toxic.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_toxic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of severe toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hC7KAZwD4fjx"
   },
   "outputs": [],
   "source": [
    "#extract dataset with Severe toxic label\r\n",
    "df_severe_toxic = df[df['severe_toxic'] == 1]\r\n",
    "#Reseting the index\r\n",
    "df_severe_toxic.set_index(['id'], inplace = True)\r\n",
    "df_severe_toxic.reset_index(level =['id'], inplace = True)\r\n",
    "# df_severe_toxic =df_severe_toxic.drop('comment_text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_severe_toxic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset with obscene comment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DozMymTMk6v4"
   },
   "outputs": [],
   "source": [
    "#extract dataset with obscens label\n",
    "df_obscene = df[df['obscene'] == 1]\n",
    "#Reseting the index\n",
    "df_obscene.set_index(['id'], inplace = True)\n",
    "df_obscene.reset_index(level =['id'], inplace = True)\n",
    "#df_obscene =df_obscene.drop('comment_text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "SGnF3auYk6v6"
   },
   "outputs": [],
   "source": [
    "#df_obscene.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset with comments labeled as \"identity_hate\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_identity_hate = df[df['identity_hate'] == 1]\n",
    "#Reseting the index\n",
    "df_identity_hate.set_index(['id'], inplace = True)\n",
    "df_identity_hate.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_identity_hate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset with all the threat comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threat = df[df['threat'] == 1]\n",
    "#Reseting the index\n",
    "df_threat.set_index(['id'], inplace = True)\n",
    "df_threat.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_threat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of comments with \"Insult\" label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insult = df[df['insult'] == 1]\n",
    "#Reseting the index\n",
    "df_insult.set_index(['id'], inplace = True)\n",
    "df_insult.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_insult.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUbpKvRXk6wR"
   },
   "source": [
    "#### Dataset with comments which have all six labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Ri59MDQck6wS"
   },
   "outputs": [],
   "source": [
    "df_6 = df[(df['toxic']==1) & (df['severe_toxic']==1) & (df['obscene']==1) & (df['threat']==1)& (df['insult']==1)& (df['identity_hate']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "1niPINFJk6wS"
   },
   "outputs": [],
   "source": [
    "df_6.set_index(['id'], inplace = True)\n",
    "df_6.reset_index(level =['id'], inplace = True) \n",
    "# df6 = df_6.drop('comment_text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Ab7ycDCN6-rN"
   },
   "outputs": [],
   "source": [
    "#df_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "KWrAExI3k6v-"
   },
   "outputs": [],
   "source": [
    "### data cleaner function\n",
    "def clean(input_str):\n",
    "    input_str = input_str.lower()\n",
    "    input_str = re.sub(r'\\d+', '', input_str)\n",
    "    input_str = re.sub(r\"n't\", \" not \", input_str)\n",
    "    input_str = re.sub(r\"can't\", \"cannot \", input_str)\n",
    "    input_str = re.sub(r\"what's\", \"what is \", input_str)\n",
    "    input_str = re.sub(r\"\\'s\", \" \", input_str)\n",
    "    input_str = re.sub(r\"\\'ve\", \" have \", input_str)\n",
    "    input_str = re.sub(r\"\\'re\", \" are \", input_str)\n",
    "    input_str = re.sub(r\"\\'d\", \" would \", input_str)\n",
    "    input_str = re.sub(r\"\\'ll\", \" will \", input_str)\n",
    "    input_str = re.sub(r\"\\'scuse\", \" excuse \", input_str)\n",
    "    input_str = re.sub(r\"i'm\", \"i am\", input_str)\n",
    "    input_str = re.sub(r\" m \", \" am \", input_str)\n",
    "    input_str = re.sub('\\s+', ' ', input_str)\n",
    "    input_str = re.sub('\\W', ' ', input_str)\n",
    "    input_str = input_str.translate(str.maketrans('','', string.punctuation))\n",
    "    input_str = input_str.strip()\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "8l4sD-muk6wG"
   },
   "outputs": [],
   "source": [
    "### Frequently used words in the obscene comments\n",
    "def make_dict(data):\n",
    "    all_word = []\n",
    "    counts = dict()\n",
    "    for i in range (0,len(data)):\n",
    "\n",
    "        ### Load input\n",
    "        input_str = data.comment_text[i]\n",
    "\n",
    "        ### Clean input data\n",
    "        processed_text = clean(input_str)\n",
    "\n",
    "        ### perform tokenization\n",
    "        tokened_text = word_tokenize(processed_text)\n",
    "\n",
    "        ### remove stop words\n",
    "        comment_word = []\n",
    "        for word in tokened_text:\n",
    "            if word not in stopwords.words('english'):\n",
    "                comment_word.append(word)\n",
    "        #print(len(comment_word))\n",
    "        all_word.extend(comment_word)\n",
    "      \n",
    "    for word in all_word:\n",
    "      if word in counts:\n",
    "          counts[word] += 1\n",
    "      else:\n",
    "          counts[word] = 1\n",
    "    \n",
    "    return all_word, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "5sSvyJ2hk6wH"
   },
   "outputs": [],
   "source": [
    "all_words, word_count = make_dict(df_obscene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "w3hO_0ej2LpV"
   },
   "outputs": [],
   "source": [
    "# Arrange the words in descening order and pick the words with minimum count\r\n",
    "def descend_odr(data, min_count):\r\n",
    "  all_words, word_count = make_dict(data)\r\n",
    "  sorted_d = dict( sorted(word_count.items(), key=operator.itemgetter(1),reverse=True))\r\n",
    "  for m,n in sorted_d.items():\r\n",
    "    if n > min_count:\r\n",
    "      print (m,n)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck 9937\n",
      "wikipedia 3678\n",
      "shit 3623\n",
      "like 3512\n",
      "nigger 3300\n",
      "fucking 3290\n",
      "suck 3235\n",
      "ass 2940\n",
      "go 2866\n",
      "u 2866\n",
      "hate 2631\n",
      "get 2300\n",
      "gay 2239\n",
      "know 2201\n",
      "page 2147\n",
      "die 2082\n",
      "faggot 2017\n",
      "fat 1970\n",
      "people 1874\n",
      "moron 1862\n",
      "bitch 1787\n",
      "hi 1691\n",
      "cunt 1545\n",
      "one 1529\n",
      "sucks 1443\n",
      "wiki 1437\n",
      "stupid 1436\n",
      "stop 1420\n",
      "talk 1403\n",
      "article 1394\n",
      "would 1383\n",
      "pig 1355\n",
      "jew 1351\n",
      "dick 1305\n",
      "user 1264\n",
      "penis 1239\n",
      "think 1236\n",
      "want 1220\n",
      "bullshit 1139\n",
      "life 1091\n",
      "block 1089\n",
      "time 1064\n",
      "asshole 1044\n",
      "wanker 1035\n",
      "dont 1030\n",
      "fag 1013\n",
      "even 1008\n",
      "bark 1001\n"
     ]
    }
   ],
   "source": [
    "descend_odr(df_toxic, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>These are the words most frequently used in toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck 7304\n",
      "suck 2535\n",
      "ass 2115\n",
      "shit 1885\n",
      "u 1611\n",
      "faggot 1571\n",
      "fucking 1457\n",
      "go 1241\n",
      "die 1156\n",
      "bitch 1113\n",
      "nigger 1012\n",
      "sucks 961\n",
      "cunt 834\n",
      "wikipedia 773\n",
      "cock 681\n",
      "fucksex 624\n",
      "yourselfgo 621\n",
      "dick 596\n",
      "fucker 588\n",
      "kill 580\n",
      "asshole 522\n",
      "cocksucker 510\n",
      "piece 502\n"
     ]
    }
   ],
   "source": [
    "descend_odr(df_severe_toxic, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>These are the words most frequently used in severe toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MhAqDiuA3Tdq",
    "outputId": "571ee676-a48a-41ea-9be5-95015da93467"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck 9863\n",
      "shit 3214\n",
      "fucking 3193\n",
      "suck 3021\n",
      "ass 2847\n",
      "nigger 2727\n",
      "u 2310\n",
      "go 2148\n",
      "wikipedia 1905\n",
      "bitch 1797\n",
      "like 1541\n",
      "cunt 1534\n",
      "get 1407\n",
      "fat 1282\n",
      "dick 1259\n",
      "faggot 1223\n",
      "know 1178\n",
      "die 1173\n",
      "bullshit 1086\n",
      "page 1082\n",
      "penis 1076\n",
      "sucks 1068\n",
      "asshole 1009\n"
     ]
    }
   ],
   "source": [
    "a = descend_odr(df_obscene, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHn2oJaok6wR"
   },
   "source": [
    "<br>These are the words most frequently used in obscene comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "die 1168\n",
      "ass 772\n",
      "kill 504\n",
      "going 294\n",
      "wikipedia 200\n",
      "block 170\n",
      "must 167\n",
      "fuck 166\n",
      "jim 158\n",
      "wales 157\n",
      "supertrll 152\n",
      "fucking 138\n",
      "ban 132\n",
      "page 128\n",
      "talk 113\n",
      "murder 107\n",
      "live 102\n",
      "fuckin 101\n"
     ]
    }
   ],
   "source": [
    "descend_odr(df_threat, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>These are the words most frequently used in severe threat comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck 7928\n",
      "fucking 2800\n",
      "suck 2792\n",
      "nigger 2781\n",
      "go 2236\n",
      "u 2220\n",
      "ass 2212\n",
      "fat 1926\n",
      "faggot 1867\n",
      "bitch 1735\n",
      "shit 1691\n",
      "like 1565\n",
      "moron 1458\n",
      "cunt 1444\n",
      "wikipedia 1430\n",
      "hi 1400\n",
      "hate 1386\n",
      "jew 1307\n",
      "get 1301\n",
      "die 1217\n",
      "know 1162\n",
      "stupid 1068\n",
      "dick 1047\n"
     ]
    }
   ],
   "source": [
    "descend_odr(df_insult,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>These are the words most frequently used in comments labeled as an insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nigger 2969\n",
      "fat 1322\n",
      "jew 1315\n",
      "gay 918\n",
      "fuck 880\n",
      "die 879\n",
      "faggot 742\n",
      "fucking 518\n",
      "huge 430\n",
      "suck 427\n",
      "shit 410\n",
      "stupid 396\n",
      "cunt 394\n",
      "like 384\n",
      "ass 374\n",
      "mexicans 365\n",
      "bitch 349\n",
      "niggas 342\n",
      "go 308\n",
      "hate 291\n",
      "bunksteve 278\n",
      "u 275\n",
      "jewish 248\n",
      "get 246\n",
      "wikipedia 234\n",
      "tommy 230\n",
      "ancestryfuck 208\n",
      "kill 197\n",
      "jews 184\n",
      "spanish 182\n",
      "people 181\n",
      "licker 181\n",
      "fan 181\n",
      "ca 180\n",
      "centraliststupid 179\n",
      "piece 171\n",
      "nigga 170\n",
      "keep 167\n",
      "drink 151\n"
     ]
    }
   ],
   "source": [
    "descend_odr(df_identity_hate,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>These are the most frequently used words in the comments labeled as identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "die 727\n",
      "di 90\n",
      "edie 90\n",
      "wikipedia 72\n",
      "en 71\n",
      "org 71\n",
      "wiki 71\n",
      "therealstephenhawkinghttp 69\n",
      "fuck 28\n",
      "bitch 27\n",
      "ass 26\n",
      "fucking 25\n",
      "rape 22\n",
      "fat 15\n",
      "going 14\n",
      "shit 13\n",
      "wheelchairi 12\n",
      "fuckin 9\n",
      "get 9\n",
      "go 7\n",
      "jew 7\n",
      "kill 7\n",
      "mother 6\n",
      "faggot 6\n",
      "fag 6\n",
      "piss 6\n"
     ]
    }
   ],
   "source": [
    "descend_odr(df_6,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>These are the most frequently used words in the comments labeled as identity_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "etc.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
