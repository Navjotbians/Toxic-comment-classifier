{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "x11nOpWkhHyt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import nltk\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import re\r\n",
    "import string\r\n",
    "import operator\r\n",
    "from sklearn import feature_extraction,model_selection,naive_bayes,pipeline,manifold,preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8crPCeN5PchF",
    "outputId": "b0783981-2455-4a32-9278-afaf98b64bbc"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.getrecursionlimit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "A6lJo6fMPev_"
   },
   "outputs": [],
   "source": [
    "# sys.setrecursionlimit(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vZnJ896ohoC-"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lgfCbNpXh7qj"
   },
   "outputs": [],
   "source": [
    "### data cleaner function\r\n",
    "def clean(input_str):\r\n",
    "    input_str = input_str.lower()\r\n",
    "    input_str = re.sub(r'\\d+', '', input_str)\r\n",
    "    input_str = re.sub(r\"n't\", \" not \", input_str)\r\n",
    "    input_str = re.sub(r\"can't\", \"cannot \", input_str)\r\n",
    "    input_str = re.sub(r\"what's\", \"what is \", input_str)\r\n",
    "    input_str = re.sub(r\"\\'s\", \" \", input_str)\r\n",
    "    input_str = re.sub(r\"\\'ve\", \" have \", input_str)\r\n",
    "    input_str = re.sub(r\"\\'re\", \" are \", input_str)\r\n",
    "    input_str = re.sub(r\"\\'d\", \" would \", input_str)\r\n",
    "    input_str = re.sub(r\"\\'ll\", \" will \", input_str)\r\n",
    "    input_str = re.sub(r\"\\'scuse\", \" excuse \", input_str)\r\n",
    "    input_str = re.sub(r\"i'm\", \"i am\", input_str)\r\n",
    "    input_str = re.sub(r\" m \", \" am \", input_str)\r\n",
    "    input_str = re.sub('\\s+', ' ', input_str)\r\n",
    "    input_str = re.sub('\\W', ' ', input_str)\r\n",
    "    input_str = input_str.translate(str.maketrans('','', string.punctuation))\r\n",
    "    input_str = input_str.strip()\r\n",
    "    return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "BKDaQt-yiBo0"
   },
   "outputs": [],
   "source": [
    "### Frequently used words in the obscene comments\r\n",
    "def make_dic(dd, stemm = False,lemm = True):\r\n",
    "    #all_word = []\r\n",
    "        ### Clean input data\r\n",
    "    processed_text = cldan(d)\r\n",
    "        ### Tokenization\r\n",
    "    processed_text = word_tokenize(processed_text)\r\n",
    "     ### remove stop words\r\n",
    "    processed_text = [word for word in processed_text if word not in stopwords.words('english')]\r\n",
    "    #all_word.append(processed_text)\r\n",
    "\r\n",
    "    ### Stemming\r\n",
    "    if stemm == True:\r\n",
    "      ps = nltk.stem.porter.PorterStemmer()\r\n",
    "      processed_text = [ps.stem(word) for word in processed_text]\r\n",
    "\r\n",
    "    ### Lemmatization\r\n",
    "    if lemm == True:\r\n",
    "      lem = nltk.stem.wordnet.WordNetLemmatizer()\r\n",
    "      processed_text = [lem.lemmatize(word) for word in processed_text]\r\n",
    "\r\n",
    "    text = \" \".join(processed_text)\r\n",
    "    \r\n",
    "    return text\r\n",
    "\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zISYQ-DfiByc",
    "outputId": "8db0397b-e09e-4d84-efdf-a7ffe29a96e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey man realli tri edit war guy constantli remov relev inform talk edit instead talk page seem care format actual info'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = df.comment_text[2]\r\n",
    "\r\n",
    "make_dict(input_str, stemm= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append the clean comments in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tc9PsGd9iCGw"
   },
   "outputs": [],
   "source": [
    "# df['clean_comment'] = df['comment_text'].apply(lambda x:make_dict(x, stemm= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "id": "UZNkUksQiCJJ",
    "outputId": "e8004035-4d87-4795-eaf9-97a46915a03a"
   },
   "outputs": [],
   "source": [
    "#df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEaMUDIJPWip"
   },
   "source": [
    "#### Reading the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Hax0tB4A8OmE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dropping the original unclean comment coloum from dataset\n",
    "df = df.drop('comment_text', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renaming the clean comment colum to comment_text for ease\n",
    "df = df.rename({'clean_comment': 'comment_text'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ca make real suggestion improvement wondered s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0           0  0000997932d777bf      0             0        0       0       0   \n",
       "1           1  000103f0d9cfb60f      0             0        0       0       0   \n",
       "2           2  000113f07ec002fd      0             0        0       0       0   \n",
       "3           3  0001b41b1c6bb37e      0             0        0       0       0   \n",
       "4           4  0001d958c54c6e35      0             0        0       0       0   \n",
       "\n",
       "   identity_hate                                       comment_text  \n",
       "0              0  explanation edits made username hardcore metal...  \n",
       "1              0  aww match background colour seemingly stuck th...  \n",
       "2              0  hey man really trying edit war guy constantly ...  \n",
       "3              0  ca make real suggestion improvement wondered s...  \n",
       "4              0                      sir hero chance remember page  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threat = df[df['threat'] == 1]\n",
    "#Reseting the index\n",
    "df_threat.set_index(['id'], inplace = True)\n",
    "df_threat.reset_index(level =['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_threat['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_vectorizer = feature_extraction.text.CountVectorizer(max_features= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 100)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bw_vectorizer.fit_transform(corpus).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF -IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = feature_extraction.text.TfidfVectorizer(max_features=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = tf_vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 100)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.53984351, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.8417654 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
